{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chaotic Systems Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlg28pVox2Vy"
      },
      "source": [
        "# Chaotic systems prediction using NN\n",
        "\n",
        "## This notebook is developed to show how well Neural Networks perform when presented with the task of predicting the trajectories of **Chaotic Systems**, this notebook is part of the work presented in *New results for prediction of chaotic systems using Deep Recurrent Neural Networks* in the journal of **Neural Processing Letters**\n",
        "\n",
        "### In this experiment RNN-LSTM, RNN-GRU and MLP neural networks are trained and tested to predict the trajectories of the chaotic systems of Lorenz, Rabinovich-Fabrikant and Rossler.\n",
        "\n",
        "## Description of this Notebook\n",
        "\n",
        "*   The initial conditions of the chaotic systems are defined in the *Chaos_Attractors* class\n",
        "*   The *NN_Identifier* class is where the neural test and training takes place, the outputs are graphs that show the performance obtained by the trained model as well as the trajectories identified by the neural network\n",
        "*  In the last cells the global parameters such as the number of epochs, layers, neurons and batch size are defined to train and predict the chaotic systems as well as the time series size. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2SBfRT6obwQ"
      },
      "source": [
        "#Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lNZ6tD9ofUk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Dense, Dropout, Masking, Embedding, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.integrate import odeint\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import math\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgXQowUIpzVW"
      },
      "source": [
        "#Save images to you Google Drive Path \n",
        "drive.mount('/content/gdrive')\n",
        "images_dir = '/content/gdrive/My Drive/Colab_Images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL_5pUJdp3Vl"
      },
      "source": [
        "#Lorenz, Rabinovich–Fabrikant and Rossler Chaotic Systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PERGydbjp0m-"
      },
      "source": [
        "class ChaosAttractors():\n",
        "    \"\"\"\n",
        "    Initial conditions for the systems to display chaotic behaviour are \n",
        "    defined as follows:\n",
        "\n",
        "    Lorenz 63 -> s = 10, r = 8/3, b = 28 and dt = 0.01\n",
        "    Fabrikant-Rabinovich -> a = 0.14, g = 0.1 and dt = 0.01\n",
        "    Rossler -> a = 0.2, b = 0.2, c = 6.3 and dt = 0.01 \n",
        "    \"\"\"\n",
        "    def __init__(self, steps, lrz_s=10, lrz_r=28, lrz_b=8/3, lrz_dt = 0.01, \n",
        "                 rab_fab_a = 0.14, rab_fab_g = 0.1, rab_fab_dt = 0.01,\n",
        "                 ros_a=0.2, ros_b=0.2, ros_c=6.3, ros_dt = 0.01):\n",
        "        self.lrz_s = lrz_s\n",
        "        self.lrz_b = lrz_b\n",
        "        self.lrz_r = lrz_r\n",
        "        self.lrz_dt = lrz_dt\n",
        "        self.rab_fab_a = rab_fab_a\n",
        "        self.rab_fab_g = rab_fab_g\n",
        "        self.rab_fab_dt = rab_fab_dt\n",
        "        self.ros_a = ros_a\n",
        "        self.ros_b = ros_b\n",
        "        self.ros_c = ros_c\n",
        "        self.ros_dt = ros_dt\n",
        "        self.steps = steps\n",
        "        \n",
        "    \"\"\"Lorenz 63 System\"\"\"    \n",
        "    def lorenz63(self):\n",
        "        xs = np.empty((self.steps + 1,))\n",
        "        ys = np.empty((self.steps + 1,))\n",
        "        zs = np.empty((self.steps + 1,))\n",
        "        \n",
        "        xs[0], ys[0], zs[0] = (1.0, 1.0, 1.0)\n",
        "        for i in range(self.steps):\n",
        "            x_dot = self.lrz_s*(ys[i] - xs[i])\n",
        "            y_dot = self.lrz_r*xs[i] - ys[i] - xs[i]*zs[i]\n",
        "            z_dot = xs[i]*ys[i] - self.lrz_b*zs[i]\n",
        "            xs[i + 1] = xs[i] + (x_dot * self.lrz_dt)\n",
        "            ys[i + 1] = ys[i] + (y_dot * self.lrz_dt)\n",
        "            zs[i + 1] = zs[i] + (z_dot * self.lrz_dt)\n",
        "        return xs, ys, zs\n",
        "    \n",
        "    \"\"\"Rabinovich–Fabrikant equations\"\"\"\n",
        "    def rabinovich_fabrikant(self):\n",
        "        xs = np.zeros((self.steps))\n",
        "       \tys = np.zeros((self.steps))\n",
        "       \tzs = np.zeros((self.steps))\n",
        "       \txs[0] ,ys[0] ,zs[0] = (-1,0,0.5)\n",
        "       \t\n",
        "       \tfor i in range(1,self.steps):\n",
        "       \t\tx = xs[i-1]\n",
        "       \t\ty = ys[i-1]\n",
        "       \t\tz = zs[i-1]\n",
        "       \t\tdx = y*(z - 1 + x*x) + self.rab_fab_g*x\n",
        "       \t\tdy = x*(3*z + 1 - x*x) + self.rab_fab_g *y\n",
        "       \t\tdz = -2*z*(self.rab_fab_a  + x*y)\n",
        "       \t\txs[i] = x+self.rab_fab_dt*dx\n",
        "       \t\tys[i] = y+self.rab_fab_dt*dy\n",
        "       \t\tzs[i] = z+self.rab_fab_dt*dz\n",
        "        return xs, ys, zs\n",
        "    \n",
        "    \"\"\"Rossler Hyperchaotic System\"\"\"\n",
        "    def rossler(self):\n",
        "        xs = np.empty([self.steps + 1])\n",
        "        ys = np.empty([self.steps + 1])\n",
        "        zs = np.empty([self.steps + 1])\n",
        "        xs[0], ys[0], zs[0] = (1.0, 1.0, 1.0)\n",
        "        \n",
        "        for i in range(self.steps):\n",
        "            x_dot = -ys[i] - zs[i]\n",
        "            y_dot = xs[i] + self.ros_a*ys[i]\n",
        "            z_dot = self.ros_b + xs[i]*zs[i] - self.ros_c*zs[i]\n",
        "            xs[i+1] = xs[i] + (x_dot * self.ros_dt)\n",
        "            ys[i+1] = ys[i] + (y_dot * self.ros_dt)\n",
        "            zs[i+1] = zs[i] + (z_dot * self.ros_dt)\n",
        "        return xs, ys, zs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVeTGVjvtbEc"
      },
      "source": [
        "# Neural characterization models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfEfqxXfqFqQ"
      },
      "source": [
        "class NNIdentifier():\n",
        "  \"\"\"\n",
        "    Neural network models to predict chaotic systems\n",
        "    The neural network models used are the RNN-LSTM, RNN-GRU and MLP\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    num_neurons : int\n",
        "        Number of neurons used in each layer of the NN\n",
        "    num_neurons : int\n",
        "        Number of layers in the NN\n",
        "    dataset : array[x ,y ,z]\n",
        "        Dataset used to train and test the NN model\n",
        "    training_epochs : int \n",
        "        Number of epochs for training the NN\n",
        "    batch_size: int\n",
        "        Size of the batch passed to the NN\n",
        "    attractor_name: string\n",
        "        Name of the chaotic system (Used for title of the trajectory graph)\n",
        "    chaos_x_series: array[x]\n",
        "        Time series of the chaotic system in the X variable\n",
        "    chaos_y_series: array[x]\n",
        "        Time series of the chaotic system in the Y variable\n",
        "    chaos_z_series: array[x]\n",
        "        Time series of the chaotic system in the Z variable\n",
        "    \"\"\"\n",
        "    def __init__(self, num_neurons, num_layers, dataset, training_epochs, batch_size, attractor_name, chaos_x_series, chaos_y_series, chaos_z_series):\n",
        "        self.num_neurons = num_neurons\n",
        "        self.num_layers = num_layers\n",
        "        self.dataset = dataset\n",
        "        self.training_epochs = training_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.trainX = []\n",
        "        self.trainY = []\n",
        "        self.testX = []\n",
        "        self.testY = []\n",
        "        self.attractor_name = attractor_name\n",
        "        self.look_back = 1\n",
        "        self.chaos_x_series = chaos_x_series\n",
        "        self.chaos_y_series = chaos_y_series\n",
        "        self.chaos_z_series = chaos_z_series\n",
        "        \n",
        "    def predict_attractor(self):\n",
        "        self.normalize_datase()\n",
        "        self.train_eval_models()\n",
        "    \n",
        "    def create_dataset(self, dataset, look_back=1):\n",
        "    \tdataX, dataY = [], []\n",
        "    \tfor i in range(len(dataset)-look_back-1):\n",
        "    \t\ta = dataset[i:(i+look_back)]\n",
        "    \t\tdataX.append(a)\n",
        "    \t\tdataY.append(dataset[i + look_back])\n",
        "    \treturn np.array(dataX), np.array(dataY)\n",
        " \n",
        "    def normalize_datase(self):\n",
        "        # Normalize Uk \n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        dataset = scaler.fit_transform(self.dataset)\n",
        "        \n",
        "        # split into train and test sets\n",
        "        train_size = int(len(dataset) * 0.6)\n",
        "        test_size = len(dataset) - train_size\n",
        "        train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "        \n",
        "        # reshape into X=t and Y=t+1\n",
        "        look_back = 1\n",
        "        self.trainX, self.trainY = self.create_dataset(train, look_back)\n",
        "        self.testX, self.testY = self.create_dataset(test, look_back)\n",
        "        \n",
        "        # reshape input to be [samples, time steps, features]\n",
        "        self.trainX = np.reshape(self.trainX, (self.trainX.shape[0], 1, self.trainX.shape[2]))\n",
        "        self.testX = np.reshape(self.testX, (self.testX.shape[0], 1, self.testX.shape[2]))\n",
        "        \n",
        "    def gru_model(self):\n",
        "        \"\"\"GRU RNN\"\"\"\n",
        "        gru_model = Sequential()\n",
        "        if(self.num_layers>1):\n",
        "            gru_model.add(GRU(self.num_neurons, input_shape=(1,3), return_sequences = True))\n",
        "            for x in range(self.num_layers):\n",
        "                gru_model.add(GRU(self.num_neurons, return_sequences = True))\n",
        "                if(x == self.num_layers-1):\n",
        "                    gru_model.add(GRU(self.num_neurons, return_sequences = False))\n",
        "        else:\n",
        "            gru_model.add(GRU(self.num_neurons, input_shape=(1,3), return_sequences = False))\n",
        "        gru_model.add(Dense(3))\n",
        "        gru_model.compile(optimizer='adam', loss='mean_squared_error', metrics =['mse','acc'])\n",
        "        seq_gru_model = gru_model.fit(self.trainX, self.trainY, epochs=self.training_epochs, batch_size=self.batch_size)\n",
        "        return gru_model, seq_gru_model\n",
        "        \n",
        "    def lstm_model(self):\n",
        "        \"\"\"LSTM RNN\"\"\"\n",
        "        lstm_model = Sequential()\n",
        "        if(self.num_layers>1):\n",
        "            lstm_model.add(LSTM(self.num_neurons, input_shape=(1,3), return_sequences = True))\n",
        "            for x in range(self.num_layers):\n",
        "                lstm_model.add(LSTM(self.num_neurons, return_sequences = True))\n",
        "                if(x == self.num_layers-1):\n",
        "                    lstm_model.add(LSTM(self.num_neurons, return_sequences = False))\n",
        "        else:\n",
        "            lstm_model.add(LSTM(self.num_neurons, input_shape=(1,3), return_sequences = False))\n",
        "        lstm_model.add(Dense(3))\n",
        "        lstm_model.compile(optimizer='adam', loss='mean_squared_error', metrics =['mse','acc'])\n",
        "        seq_lstm_model = lstm_model.fit(self.trainX, self.trainY, epochs=self.training_epochs, batch_size=self.batch_size)\n",
        "        return lstm_model, seq_lstm_model\n",
        "        \n",
        "    def mlp_model(self):\n",
        "        \"\"\"MLP NN\"\"\"\n",
        "        mlp_model = Sequential()\n",
        "        mlp_model.add(Dense(self.num_neurons, input_shape=(1,3)))\n",
        "        if(self.num_layers>1):\n",
        "            for x in range(self.num_layers): \n",
        "                mlp_model.add(Dense(self.num_neurons))\n",
        "        mlp_model.add(Flatten())\n",
        "        mlp_model.add(Dense(3))\n",
        "        mlp_model.compile(optimizer='adam', loss='mean_squared_error', metrics =['mse','acc'])\n",
        "        seq_mlp_model = mlp_model.fit(self.trainX, self.trainY, epochs=self.training_epochs, batch_size=self.batch_size)\n",
        "        return mlp_model, seq_mlp_model\n",
        "        \n",
        "        \n",
        "    def predict_eval_model(self, model, label_nn):\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        dataset = scaler.fit_transform(self.dataset)\n",
        "        # make predictions\n",
        "        trainPredict = model.predict(self.trainX)\n",
        "        testPredict = model.predict(self.testX)\n",
        "        # invert predictions\n",
        "        trainPredict = scaler.inverse_transform(trainPredict)\n",
        "        self.trainY = scaler.inverse_transform(self.trainY)\n",
        "        testPredict = scaler.inverse_transform(testPredict)\n",
        "        self.testY = scaler.inverse_transform(self.testY)\n",
        "        # shift train predictions for plotting\n",
        "        trainPredictPlot = np.empty_like(dataset)\n",
        "        trainPredictPlot[:, :] = np.nan\n",
        "        trainPredictPlot[self.look_back:len(trainPredict)+self.look_back, :] = trainPredict\n",
        "        # shift test predictions for plotting\n",
        "        testPredictPlot = np.empty_like(dataset)\n",
        "        testPredictPlot[:, :] = np.nan\n",
        "        testPredictPlot[len(trainPredict)+(self.look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "        # get values to graph\n",
        "        val_xtrain = []\n",
        "        val_ytrain = []\n",
        "        val_ztrain = []\n",
        "        for x in range(len(trainPredictPlot)):\n",
        "          val_xtrain.append(trainPredictPlot[x][0])\n",
        "          val_ytrain.append(trainPredictPlot[x][1])\n",
        "          val_ztrain.append(trainPredictPlot[x][2])\n",
        "        \n",
        "        val_xtest = []\n",
        "        val_ytest = []\n",
        "        val_ztest = []\n",
        "        for x in range(len(testPredictPlot)):\n",
        "          val_xtest.append(testPredictPlot[x][0])\n",
        "          val_ytest.append(testPredictPlot[x][1])\n",
        "          val_ztest.append(testPredictPlot[x][2])\n",
        "        #Graph\n",
        "        fig = plt.figure()\n",
        "        ax = fig.gca(projection='3d')\n",
        "        \n",
        "        ax.plot(self.chaos_x_series, self.chaos_y_series, self.chaos_z_series, lw=0.8, label=self.attractor_name)\n",
        "        ax.plot(val_xtrain, val_ytrain, val_ztrain, lw=0.5,label='Train Set')\n",
        "        ax.plot(val_xtest, val_ytest, val_ztest, lw=0.5, label='Test Set')\n",
        "        legend = plt.legend(loc='upper left', shadow=True, fontsize='xx-large')\n",
        "        fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "        ax.set_xlabel(\"X Axis\", fontsize=20)\n",
        "        ax.set_ylabel(\"Y Axis\", fontsize=20)\n",
        "        ax.set_zlabel(\"Z Axis\", fontsize=20)\n",
        "        ax.set_title(self.attractor_name + ' - '+label_nn)\n",
        "        plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "        plt.savefig(f'{images_dir}/{self.attractor_name}_{label_nn}.eps', format='eps')\n",
        "        plt.show()\n",
        "\n",
        "      \n",
        "    def graph_eval_model(self, gru_train_loss, lstm_train_loss, mlp_train_loss, gru_train_acc, lstm_train_acc, mlp_train_acc):\n",
        "        \"\"\"Loss evaluation and graph\"\"\"\n",
        "        xc = range(self.training_epochs)\n",
        "        plt.figure()\n",
        "        plt.plot(xc, gru_train_loss, label='MSE - GRU')\n",
        "        plt.plot(xc, lstm_train_loss, label='MSE - LSTM')\n",
        "        plt.plot(xc, mlp_train_loss, label='MSE - MLP')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Error %')\n",
        "        plt.yscale('log')\n",
        "        plt.title('MSE for the '+ self.attractor_name)\n",
        "        legend = plt.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "        \"\"\"Accuracy evaluation and graph\"\"\"\n",
        "        plt.figure()\n",
        "        plt.plot(xc, gru_train_acc, label ='Accuracy - GRU')\n",
        "        plt.plot(xc, lstm_train_acc, label ='Accuracy - LSTM')\n",
        "        plt.plot(xc, mlp_train_acc, label ='Accuracy - MLP')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy %')\n",
        "        plt.title('Accuracy for the '+ self.attractor_name+' with '+str(self.num_layers)+' layers - '+str(self.num_neurons)+' neurons')\n",
        "        legend = plt.legend(loc='lower right', shadow=True, fontsize='x-large')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "        \n",
        "    def eval_model(self, model, seqModel):\n",
        "        loss_and_metrics = model.evaluate(self.testX, self.testY, batch_size=self.batch_size)\n",
        "        train_loss = seqModel.history['mse']\n",
        "        train_acc  = seqModel.history['acc']\n",
        "        return train_loss, train_acc\n",
        "    \n",
        "    def train_eval_models(self):\n",
        "        \"\"\"Train NN Models\"\"\"\n",
        "        gru_model, seq_gru_model = self.gru_model()\n",
        "        lstm_model, seq_lstm_model = self.lstm_model()\n",
        "        mlp_model, seq_mlp_model = self.mlp_model()\n",
        "        \n",
        "        \"\"\"Eval NN Models\"\"\"\n",
        "        gru_train_loss, gru_train_acc = self.eval_model(gru_model, seq_gru_model)\n",
        "        lstm_train_loss, lstm_train_acc = self.eval_model(lstm_model, seq_lstm_model)\n",
        "        mlp_train_loss, mlp_train_acc = self.eval_model(mlp_model, seq_mlp_model)\n",
        "        \n",
        "        \"\"\"Graph NN Eval Model\"\"\"\n",
        "        self.graph_eval_model(gru_train_loss, lstm_train_loss, mlp_train_loss, gru_train_acc, lstm_train_acc, mlp_train_acc)\n",
        "        \n",
        "        \"\"\"Graph NN Predict Model\"\"\"\n",
        "        self.predict_eval_model(gru_model, 'GRU')\n",
        "        self.predict_eval_model(lstm_model, 'LSTM')\n",
        "        self.predict_eval_model(mlp_model, 'MLP')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2iUat5Ith7n"
      },
      "source": [
        "# Format dataset to pass it into the NN\n",
        "def create_dataset(x,y,z):\n",
        "    dataset = []\n",
        "    for i in range(len(x)):\n",
        "        dataset.append([x[i], y[i], z[i]])\n",
        "    return dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePcdKi8Rw9mI"
      },
      "source": [
        "# Global parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUj3Z4VIw_5z"
      },
      "source": [
        "# Number of neurons \n",
        "num_neurons = 128\n",
        "# Number of layers\n",
        "num_layers = 5\n",
        "# Number of epochs\n",
        "epochs = 10\n",
        "# Batch size\n",
        "batch_size = 32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-nYth6iweA1"
      },
      "source": [
        "# Predicting Lorenz, Rabinovich-Fabrikant and Rossler systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSpOPvKAwdhg"
      },
      "source": [
        "# Define length of the chaotic time series\n",
        "attractors_series  = ChaosAttractors(10000)\n",
        "# Obtain the time series for the Lorenz systems\n",
        "lorenz_x, lorenz_y, lorenz_z = attractors_series.lorenz63()\n",
        "# Create dataset to pass it to the NN\n",
        "dataset = create_dataset(lorenz_x, lorenz_y, lorenz_z)\n",
        "# Instantiate the class to evaluate the prediction with the previously defined parameters\n",
        "nn_identifier = NNIdentifier(num_neurons, num_layers, dataset,epochs,batch_size,'Lorenz Chaotic System',lorenz_x, lorenz_y, lorenz_z)\n",
        "# Start evaluation\n",
        "nn_identifier.predict_attractor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jba3qr3RwbUR"
      },
      "source": [
        "# Define length of the chaotic time series\n",
        "attractors_series  = ChaosAttractors(50000)\n",
        "# Obtain the time series for the Lorenz systems\n",
        "rab_x, rab_y, rab_z = attractors_series.rabinovich_fabrikant()\n",
        "# Create dataset to pass it to the NN\n",
        "dataset = create_dataset(rab_x, rab_y, rab_z)\n",
        "# Instantiate the class to evaluate the prediction with the previously defined parameters\n",
        "nn_identifier = NNIdentifier(num_neurons, num_layers, dataset,epochs,batch_size,'Rabinovich–Fabrikant Equations',rab_x, rab_y, rab_z)\n",
        "# Start evaluation\n",
        "nn_identifier.predict_attractor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFlXTT0UxpJO"
      },
      "source": [
        "# Define length of the chaotic time series\n",
        "attractors_series  = ChaosAttractors(50000)\n",
        "# Obtain the time series for the Lorenz systems\n",
        "ros_x, ros_y, ros_z = attractors_series.rossler()\n",
        "# Create dataset to pass it to the NN\n",
        "dataset = create_dataset(ros_x, ros_y, ros_z)\n",
        "# Instantiate the class to evaluate the prediction with the previously defined parameters\n",
        "nn_identifier = NNIdentifier(num_neurons, num_layers, dataset,epochs,batch_size,'Rossler System',ros_x, ros_y, ros_z)\n",
        "# Start evaluation\n",
        "nn_identifier.predict_attractor()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
